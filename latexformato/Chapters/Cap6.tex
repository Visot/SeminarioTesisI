\chapter{Conclusiones y Trabajo Futuro}
En este capítulo se describirán las conclusiones generales que se encontraron al probar y estudiar los distintos métodos de optimización utilizados para el proceso de acelerar el entrenamiento de nuestra 2 redes neuronales convolucionales en los dataset CIFAR-10 y CIFAR-100.\\ Además, se propondrán algunas mejoras para que el trabajo obtenga mejores resultados.


\section{Conclusiones}


\begin{itemize}

\item[•] Los métodos de optimización Adam y RMSprop obtuvieron los mejores resultados de precisión en ambas pruebas.

\item[•] A pesar de que el método de optimización Adam fue propuesto a partir del RMSprop. Adam fue superado en algunas de pruebas realizadas.
\item[•] Entre los métodos adaptativos Adam, RMSprop y Adagrad . Solo este último obtuvo los peores resultados, esto se debió a su dificultad de trabajar con la suma de las gradientes al cuadrado lo cual poco a poco redujo su tasa de aprendizaje.
\item[•] El RMSprop como una mejora del Adagrad, obtuvó mejores resultados que este último. Esto debido a que RMSprop trabaja con el promedio de la raíz de la gradiente anterior y tasas de decaimiento para controlar el problema de la disminución de la tasa de aprendizaje del método Adagrad.
\item[•] Adam es el método que tiene un decaimiento más acelerado al calcular el error en la función de costo cross-entropy.

\end{itemize}


\section{Trabajo Futuro}
El propósito general de este seminario I fue adquirir el conocimiento y experiencia necesarios para poder trabajar con redes neuronales profundas. Los métodos de optimización fueron una manera de introducirme al área de las redes convolucionales y comprender las ventajas y desventajas de algunos métodos. \\
Los temas de aprendizaje automático y en particular del aprendizaje profundo son muy amplios y en este seminario se trato de acoplar los temas pero no se realizó un análisis más detallado debido a la amplitud del área. \\
En el Seminario II se trabajará con más detalle el campo de redes neuronales convolucionales, además se tratará de diseñar un red neuronal convolucional y comparar este modelo con algunos actualmente usados. Además de realizar un implementación más interactiva .\\ Este seminario fue limitado debido a la capacidad de la tarjeta gráfica usada ya que en algunos ensayos la memoria era insuficiente para el futuro seminario se planea realizar las pruebas en mejores equipos como por ejemplo contratar servicios de máquinas virtuales de Amazon u otro proveedor.



%\afterpage{\blankpage}\textsl{}